# -*- coding: utf-8 -*-
"""SUBMISSION_ANTM_FIKS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gk4nIaPC3E5KF3rrmKSyZlWWoegNSJTl

# Mengambil dataset dari Yahoo Finance untuk dataset PT Aneka Tambang tbk
"""

import yfinance as yf

stock = yf.Ticker('ANTM.JK')
data = stock.history(period='3y')
data

data.shape

"""# Import Library"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import mean_squared_error

"""# Analisis Data"""

data.info()

data.describe()

import seaborn as sns
numeric_df = data.select_dtypes(include=[np.number])
if numeric_df.shape[1] >= 4:
    plt.figure(figsize=(10,8))
    corr = numeric_df.corr()
    sns.heatmap(corr, annot=True, cmap='coolwarm')
    plt.title ('Corelation Heatmap of Numeric Features')
    plt.show()
else:
    print('Tidak cukup kolom untuk membuat korelasi heatmap')

data.drop(['Dividends','Stock Splits'], axis=1, inplace=True)
data

data.reset_index(inplace=True)
data['Date'] = pd.to_datetime(data['Date'], errors='coerce')

data.info()

invalid_dates = data['Date'].isnull().sum()
print(f'Number of invalid dates: {invalid_dates}')

if invalid_dates > 0:
    data = data.dropna(subset=['Date'])
    print('Dropped rows with invalid dates')

display(data.head())

if numeric_df.shape[1] >1:
    sns.pairplot(numeric_df)
    plt.suptitle('Pairplot of Numeric Features', y=1.02)
    plt.show()

plt.figure(figsize=(8,6))
sns.boxplot(y=data['Volume'])
plt.title ('Box Plot of Volume Traded')
plt.show()

data['Year'] = data['Date'].dt.year
avg_prices = data.groupby('Year')[['Open', 'Close', 'High', 'Low']].mean().reset_index()
plt.figure(figsize=(10, 6))
sns.barplot(x='Year', y='Close', data=avg_prices, palette='viridis')
plt.title('Average Close Price by Year')
plt.show()

"""# Preprocessing"""

def prepare_train_df(data_series, data_input=6):
    X, y = [], []

    for i in range(len(data_series) - data_input):
        X.append(data_series[i:i + data_input].flatten())  # Gunakan flatten/ravel
        y.append(data_series[i + data_input][0])  # Ambil angka scalar

    X_df = pd.DataFrame(X, columns=[f'x{i+1}' for i in range(data_input)])
    y_df = pd.Series(y, name='y')

    train_df = pd.concat([X_df, y_df], axis=1)
    return train_df

data_series = data['Close'].values.reshape(-1, 1)

# Normalisasi
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data_series)

train_df = prepare_train_df(data_scaled, data_input=6)
train_df

#Memisahkan fitur (X) dan target (y)
X = train_df.drop(columns='y').values
y = train_df['y'].values

# Reshape X menjadi (samples, timesteps, features)
X = X.reshape((X.shape[0], X.shape[1], 1))

# Split data
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

"""# Modeling"""

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam

# Definisikan model yang lebih kompleks
model = Sequential()
model.add(LSTM(100, return_sequences=True, input_shape=(6, 1)))  # Lapisan LSTM pertama dengan lebih banyak unit
model.add(Dropout(0.3))  # Dropout untuk mencegah overfitting
model.add(LSTM(50, return_sequences=False))  # Lapisan LSTM kedua
model.add(Dropout(0.3))  # Dropout kedua
model.add(Dense(25, activation='relu'))  # Lapisan Dense tambahan dengan aktivasi ReLU
model.add(Dense(1))  # Output layer
model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))

# Callback EarlyStopping
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=15,  # Lebih sabar untuk hasil yang lebih baik
    restore_best_weights=True,
    verbose=1
)

# Callback ReduceLROnPlateau untuk mengurangi learning rate jika tidak ada perbaikan
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,  # Kurangi learning rate menjadi 20% dari sebelumnya
    patience=5,  # Tunggu 5 epoch sebelum mengurangi
    min_lr=0.00001,  # Batas minimum learning rate
    verbose=1
)

# Latih model dengan early stopping dan reduce learning rate
history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=100,  # Tambah jumlah epoch
    batch_size=32,  # Ubah batch size untuk stabilitas pelatihan
    verbose=1,
    callbacks=[early_stopping, reduce_lr]
)

"""# Evaluasi Model"""

# Evaluasi model
train_predictions = model.predict(X_train)
test_predictions = model.predict(X_test)

# Hitung RMSE untuk data train dan test
train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))
test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))

print(f"Train RMSE: {train_rmse}")
print(f"Test RMSE: {test_rmse}")

# Tampilkan ringkasan model
model.summary()

from sklearn.metrics import mean_absolute_percentage_error
# Pastikan data dalam skala asli (inverse transform)
y_train_rescaled = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()
y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
train_predictions_rescaled = scaler.inverse_transform(train_predictions).flatten()
test_predictions_rescaled = scaler.inverse_transform(test_predictions).flatten()
# Hitung MAPE
train_mape = mean_absolute_percentage_error(y_train_rescaled, train_predictions_rescaled) * 100
test_mape = mean_absolute_percentage_error(y_test_rescaled, test_predictions_rescaled) * 100
print(f"Train MAPE: {train_mape:.3f}%")
print(f"Test MAPE: {test_mape:.3f}%")

"""# Visualisasi Grafik Harga Actual dan Prediksi"""

plt.figure(figsize=(12, 6))
plt.plot(y_test, label='Actual')
plt.plot(test_predictions, label='Predicted')
plt.title("Forecasting Harga Close Saham Antam")
plt.xlabel("Time")
plt.ylabel("Close Price")
plt.legend()
plt.grid(True)
plt.show()

"""# Forecasting Untuk 30 hari kedepan"""

# Forecasting 30 hari ke depan
data_input = 6
last_sequence = data_scaled[-data_input:]  # Ambil 6 hari terakhir
forecast = []
future_dates = pd.date_range(start='2025-05-23', periods=30, freq='D')  # Mulai dari 23 Mei 2025

for _ in range(30):
    # Ubah bentuk yang benar untuk prediksi (jumlah sampel, jumlah timestep, jumlah fitur)
    last_sequence_reshaped = last_sequence.reshape((1, data_input, 1)) # Ubah bentuk untuk prediksi, dengan asumsi 1 fitur

    next_pred = model.predict(last_sequence_reshaped, verbose=0)  # Prediksi
    forecast.append(next_pred[0, 0])  # Simpan prediksi

    # Perbarui urutan untuk iterasi berikutnya
    next_sequence = last_sequence[1:]  # Geser jendela
    next_sequence = np.vstack((next_sequence, np.array([[next_pred[0, 0]]])))  # Append the new prediction as a new step in the sequence
    last_sequence = next_sequence
# Ubah kembali ke nilai asli (Inverse transform)
forecast = np.array(forecast).reshape(-1, 1)

forecast_rescaled = scaler.inverse_transform(forecast)# Ubah kembali harga Close yang diprediksi ke skala asli

# Buat DataFrame untuk hasil
forecast_df = pd.DataFrame({
    'Date': future_dates,
    'Predicted_Close': forecast_rescaled.flatten() # Flatten the results to a 1D array
})

print(forecast_df)

# Pastikan y_test dan test_predictions sudah dalam skala asli
y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
test_predictions_rescaled = scaler.inverse_transform(test_predictions.reshape(-1, 1)).flatten()

# Asumsikan y_test adalah bagian dari data historis, kita perlu tanggal untuk sumbu x
test_dates = pd.date_range(start='2025-04-01', periods=len(y_test), freq='D')  # Sesuaikan start date

# Tanggal untuk forecast sudah ada di forecast_df
forecast_dates = forecast_df['Date']
forecast_values = forecast_df['Predicted_Close']

# Plotting
plt.figure(figsize=(14, 6))
plt.plot(test_dates, y_test_rescaled, label='Data Test Aktual', color='blue', linewidth=2)
plt.plot(test_dates, test_predictions_rescaled, label='Data Test Prediksi', color='orange', linestyle='--', linewidth=2)

# Plot forecast 30 hari ke depan, dimulai dari akhir prediksi test
forecast_start_date = test_dates[-1] + pd.Timedelta(days=1)  # Mulai dari hari setelah data test
extended_dates = pd.date_range(start=forecast_start_date, periods=30, freq='D')

# Plot forecast 30 hari ke depan
plt.plot(extended_dates, forecast_values, label='Prediksi 30 Hari ke Depan', color='green', linestyle='-', linewidth=2, marker='o', markersize=4)
plt.axvline(x=forecast_start_date, color='gray', linestyle='--', label='Awal Prediksi 30 Hari')
plt.title("Perbandingan Harga Close Saham Antam: Data Test dan Prediksi 30 Hari ke Depan", fontsize=14, pad=15)
plt.xlabel("Tanggal", fontsize=12)
plt.ylabel("Harga Close (IDR)", fontsize=12)

# Format sumbu x (tanggal)
plt.gcf().autofmt_xdate()  # Rotasi tanggal agar lebih mudah dibaca
plt.gca().xaxis.set_major_locator(plt.MaxNLocator(10))  # Batasi jumlah tick pada sumbu x

# Format sumbu y (harga)
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))  # Format harga dengan pemisah ribuan
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()